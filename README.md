# kindfs
Index FS into a database, then easily make queries e.g. to find duplicates files/dirs, or mount the index with FUSE.

At the moment, the only DB supported is SQLite3.

Files are scanned with their metadata (e.g. file permissions, size, etc), filetype (from libmagic), and hashed contents (from xxhash). A pseudo-hash is then generated for dirs based on the dir contents (hashes from subfiles and pseudo-hash from subdirs). It is assumed that two files or dirs are "likely identical" when they have the same size and same hash. WARNING : since scanning speed was important to me, the hash is only made on the first/middle/last 1 MB of a file i.e. two files of identical size and different contents may exhibit the same hash (this is why (among other things) you should always double-check when this program identifies and returns candidate duplicate files/dirs).

Indexing should properly support (and not fail) when a part of the filesystem uses a different encoding (e.g. an old backup)

This program is in early phase and still not finished. Expect bugs ! The DB schema is simple but not optimal (and certainly not 3NF), and some informations are duplicate (e.g. 'parentdir/name' is equivalent to 'path', but all 3 fields were convenient for performance with sqlite indexes and FUSE)

## Usage
* `kindfs RESETDB <dbfile> <path>` : creates the sqlite file dbfile and scans the filesystem under path/
  * For performance, it is strongly adviced to have the DB on an SSD or in RAM, noting that DB can have a size around 1/1000th of the scanned data in typical cases: e.g. mine is 6 GB big after indexing my 6 TB NAS, but your mileage may vary e.g. if you have only few very big files...
* `kindfs FUSEFS <dbfile> <mountpoint>` : mounts the DB under mountpoint/ using FUSE (read-only at the moment, and only tested on Linux !). Then any tools including `diff -r` and `find` can be used.
  * Notice that `st_size` is mapped to the pseudo file contents generated by the FUSEFS (where files are all text files containing the hash+length of the real indexed file in the DB), and is different from the exposed size from `st_blocks` (which maps the real size of the file in the DB). This enables mc and du to report the real file size, while text editors can also properly read and show the summarized contents.
* `kindfs DUMP <dbfile> <dir>` : dumps the contents of an indexed dir, with hashes and sizes in front of paths
* `kindfs ISINCLUDED <dbfile> <dir1> <dir2>` : checks whether all files from dir1 are present in dir2 (regardless of files/dirs structure). This is very convenient to eliminate duplicates ! Also displays all entries from dir1 that are not in dir2
* `kindfs DIFF <dbfile> <dir1> <dir2>` : equivalent to `kindfs ISINCLUDED <dbfile> <dir1> <dir2>` + `kindfs ISINCLUDED <dbfile> <dir2> <dir1>` i.e. will display all files from one side that are not on the other side
* `kindfs DUPS <dbfile> <dir>` : returns the biggest duplicate dirs/files in the DB. Dir may be empty with `''`.
  * N.B. If the original FS is mounted (e.g. from a NAS), it checks whether those duplicates are still there.
* (more to come once it is better tested...)

## DISCLAIMER
You should read and understand the GPLv3 license (including their sections "Disclaimer of Warranty" and "Limitation of Liability"). In particular : although this tool can help detecting duplicate files, it may contain bugs, return wrong informations, behave in unintended ways. Use this software at your own risk, and it is adviced to double-check the results and never delete files/dirs unless you are sure of what you are doing !
